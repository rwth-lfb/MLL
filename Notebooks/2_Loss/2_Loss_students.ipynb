{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Laboratory\n",
    "Institute of Imaging and Computer Vision, RWTH Aachen\n",
    "\n",
    "Version SS2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2: Loss and Metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals of this session\n",
    "\n",
    "After this session, you will have an understanding of the following losses and/or metrics:\n",
    "\n",
    "- MSE, MAE\n",
    "- (Binary) CE\n",
    "\n",
    "- Cosine Similarity\n",
    "\n",
    "- Accuracy\n",
    "- F-1 Score\n",
    "- ROC\n",
    "  \n",
    "- Dice for segmentation\n",
    "- *Optional: IoU for segmentation or detection\n",
    "\n",
    "- SSIM\n",
    "- *Optional: PSNR\n",
    "\n",
    "\n",
    "**Note:** We will work with `pytorch` and `torchmetrics` in this session. You are allowed to use any torch [`Math operations (url)`](https://pytorch.org/docs/stable/torch.html#math-operations) in your own implementations and not allowed to use anything in `torch.nn.SomeLoss()` or `torchmetrics.SomeMetric()`. After implementing your version, you can call the losses from `torch.nn.SomeLoss()` or `torchmetrics.SomeMetric()` to verify your numerical results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**>> Time Management**\n",
    "  \n",
    "**>> There are 7 mandatory losses/metrics and you can plan a 15min time slot for each one on average (note that the complexities of them have a high variance). Not as fast as expected? No problem at all: you will have ca. 60min buffer time. Still not completed? You can continue with the last piece at home.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MSE, MAE\n",
    "\n",
    "We can then calculate the Mean Sqaured Error (MSE) loss (i.e., squared L2 norm) or Mean Absolute Error (MAE) loss (i.e., L1 norm) to obtain the difference between our predictions and the ground-truths. Here're the formulae:\n",
    "\n",
    "$ MAELoss_n = |x_n - y_n|$\n",
    "\n",
    "$ MSELoss_n = (x_n - y_n)^2$\n",
    "\n",
    "These losses are usually used for regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Implement MSE and MAE losses by your own and check the results with pytorch. Average the results if they are multi-dimensional with `mean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "import torch\n",
    "\n",
    "input = torch.randn(100, )\n",
    "target = torch.randn(100, )\n",
    "\n",
    "# Do not use torch.nn.SomeLoss()\n",
    "# Your Code Here\n",
    "\n",
    "# MAEloss =\n",
    "# MSEloss = \n",
    "# print(f'MAE: {MAEloss}, MSE: {MSEloss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE \n",
    "# Use torch.nn.SomeLoss()\n",
    "# Your Code Here\n",
    "\n",
    "# MAEloss =\n",
    "# MSEloss = \n",
    "# print(f'MAE: {MAEloss}, MSE: {MSEloss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Binary) Cross Entropy (CE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement CE loss for a classification task. Say there're 10 possible classes and we can use a so-called one-hot vector to represent the ground-truth: 0 means \"not this class\" and 1 means \"yes it's this class\". Correspondingly, we can use a vector containing probabilities for the predictions. This implies that the sum of the probability vector is 1 and each element is in [0,1]. In the following example, we have 5 predictions such that our complete results are of 5x10.\n",
    "\n",
    "$\\displaystyle CELoss = -\\sum_{c=1}^C \\log \\frac{\\exp (x_c)}{\\sum_{i=1}^C \\exp (x_i)} y_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE\n",
    "# input is of size N x C = 5 x 10. Note that they are not probabilities yet!\n",
    "input = torch.randn(5, 10)  # * 100\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 9, 0, 0, 4])\n",
    "\n",
    "# Do not use torch.nn.SomeLoss()\n",
    "# Your Code Here\n",
    "\n",
    "# CEloss = \n",
    "# print(f'CE: {CEloss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the torch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE\n",
    "# Use torch.nn.SomeLoss()\n",
    "# Your Code Here\n",
    "\n",
    "# CEloss = \n",
    "# print(f'CE: {CEloss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Cross Entropy loss is implemented in PyTorch as the combined `LogSoftmax()` on an input, followed by `NLLLoss()`. This means, by default, a softmax activation is already included in `CrossEntropyLoss()`. Please calculate CE with these two functions and check the result. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why `Softmax`+`CE` is better implemented as `LogSoftmax`+`NLL`?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE\n",
    "# Use torch.nn.SomeLoss()\n",
    "# Your Code Here\n",
    "\n",
    "# CEloss = \n",
    "# print(f'CE: {CEloss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Now you can multiply the `input` by 100, check the loss values of 3 versions of implementation. This is a useful trick called [LogSumExp](https://w.wiki/9hGY).\n",
    "\n",
    "**Note:** As suggested by pytorch, it's better (faster) to use class indices in `target`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Try out `BCELoss()` and `BCEWithLogitsLoss()`. Note the different activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCE\n",
    "# Your Code Here\n",
    "input_bce = torch.randn(3, 2)\n",
    "target_bce = torch.rand(3, 2)\n",
    "\n",
    "# BCEloss = \n",
    "# print(f'BCE: {BCEloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cosine Similarity\n",
    "\n",
    "$\\displaystyle cos_{sim}(x,y) = \\frac{x \\cdot y}{||x|| \\cdot ||y||} =\n",
    "\\frac{\\sum_{i=1}^n x_i y_i}{\\sqrt{\\sum_{i=1}^n x_i^2}\\sqrt{\\sum_{i=1}^n y_i^2}}$\n",
    "\n",
    "**Questions:** Describe the geometric interpretation of cosine simularity.\n",
    "\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TASK**: We have 4 row vectors in the `target` and `preds` tensors. Calculate cosine similarity of each pair and show 4 cosine similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "target = torch.tensor([[1, 2, 3, 4],[1, 2, 3, 4],[1, 2, 3, 4],[1, 2, 3, 4]], dtype=torch.float32)\n",
    "preds = torch.tensor([[1, 2, 3, 4],[0.1, 0.2, 0.3, 0.4],[-1, -2, -3, -4],[-9, 1, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "# Do not use torch.nn.SomeLoss() or torchmetrics\n",
    "# Your Code Here\n",
    "# Do not use 'reduction'\n",
    "\n",
    "# cos_sim =     # a tensor of size (4,)\n",
    "# print(f'cos_sim: {cos_sim}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the torchmetrics version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "import torchmetrics\n",
    "# Use torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# cos_sim = \n",
    "# print(f'cos_sim: {cos_sim}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accuracy\n",
    "\n",
    "Say there're 2 deseases A and B and we want to diagnose them. Now we have a 3-class task: healthy, A, B. If we have 100 samples, where 80 are healthy, 12 have A and 8 have B.\n",
    "\n",
    "$\\displaystyle \\text{Accuracy} = \\frac{1}{N}\\sum_i^N 1(y_i = \\hat{y}_i)$\n",
    "\n",
    "**TASK:** Calculate accuracy with your own implementation and torchmetrics for this multiclass task. Experiment with different average approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "target = torch.tensor([0]*80 + [1]*12 + [2]*8)\n",
    "preds = torch.tensor([0]*86 + [1]*10 + [2]*4)\n",
    "\n",
    "# Do not use torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# accuracy =\n",
    "# print(f'accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "# Use torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# accuracy =\n",
    "# print(f'accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which reduction (average approach) would you prefer and why?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "We experiment with the **binary** ROC in the following. We define 11 thresholds from 0 to 1 with a step of 0.1 and calculate the true positive rate (TPR, aka **sensitivity** or **recall**) and false positive rate (FPR) w.r.t. each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "preds = torch.rand(100)\n",
    "target = torch.randint(2, (100,))\n",
    "thresholds = torch.linspace(1, 0, 11)   # 1., 0.9, 0.8, ..., 0.\n",
    "\n",
    "# Do not use torch.nn.SomeLoss() or torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# print(f\"{'threshold':^10}{'fpr':^10}{'tpr':^10}\")  # print header\n",
    "# for th in thresholds:\n",
    "# \n",
    "#     tpr = \n",
    "#     fpr = \n",
    "#     print(f\"{th:^10.1f}{fpr:^10.4f}{tpr:^10.4f}\")  # print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the torchmetrics version. We can also plot the ROC curve effortlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "%matplotlib inline\n",
    "\n",
    "# Use torchmetrics\n",
    "# Your Code Here\n",
    "# fpr, tpr, thresh = \n",
    "\n",
    "# print(f\"{'threshold':^10}{'fpr':^10}{'tpr':^10}\") \n",
    "# for th,fpr_,tpr_ in zip(thresh, fpr, tpr):\n",
    "#     print(f\"{th:^10.1f}{fpr_:^10.4f}{tpr_:^10.4f}\")\n",
    "\n",
    "# fig_, ax_ = metric.plot(score=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the predictions are random, the AUROC should be around 0.5 ðŸŽ°\n",
    "\n",
    "**Qestions:** What is AUROC?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Optional:** Experiment with multiclass and multilabel versions of ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. SÃ¸rensenâ€“Dice Coefficient\n",
    "\n",
    "Thorvald **SÃ¸rensen** (1902-1973), Danish botanist and biologist. \n",
    "\n",
    "Lee R. **Dice** (1887-1977), American ecologist and geneticist.\n",
    "\n",
    "We will use Dice score for segmentation tasks:\n",
    "$\\displaystyle \\text{Dice} = \\frac{2|X\\bigcap Y|}{|X| + |Y|}$\n",
    "\n",
    "Imagine we have a yorkshire picture and a bit wrongly predict the segmentation of it. Now we want to calculate the Dice score on the segmentation mask and the ground-truth mask. The background is 2 and the yorkshire is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICE\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "yorkshire = io.imread('src/yorkshire_terrier_198.jpg')\n",
    "gt = io.imread('src/yorkshire_gr.png')\n",
    "pred = io.imread('src/yorkshire_pred.png')\n",
    "\n",
    "f, axarr = plt.subplots(1,3, figsize=(15,40))\n",
    "axarr[0].imshow(yorkshire)\n",
    "axarr[1].imshow(gt)\n",
    "axarr[2].imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Calculate Dice with ignored background. Again, first implement your own version and then check with torchmetrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICE\n",
    "# Do not use torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# def dice_(pred, gt, ignore_index=2):\n",
    "\n",
    "#     intersect = \n",
    "#     union = \n",
    "#     return 2 * intersect / union\n",
    "\n",
    "\n",
    "print(f'Dice: {dice_(pred, gt, ignore_index=2)}')\n",
    "\n",
    "# Use torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# dice =\n",
    "# print(f'Dice: {dice(torch.tensor(pred), torch.tensor(gt))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Structural Similarity Index Measure (SSIM)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning for [ailurophobia](https://en.wikipedia.org/wiki/Ailurophobia): there will be some cat pictures!*\n",
    "\n",
    "We first illustrate some differently processed images and calculate SSIM of each of them to the original one. \n",
    "\n",
    "**Note** that we will use a Gaussian kernel ($11\\times 11$) to calculate means and variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = io.imread('src/cat.png') / 255.\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "img_lowres = transform.resize(transform.resize(img, (int(h/3), int(w/3))), (h, w)) \n",
    "img_rot = transform.rotate(img, 180)\n",
    "img_fade = img / 2.\n",
    "img_flip = np.fliplr(img)\n",
    "img_shift = np.zeros_like(img)\n",
    "img_shift[20:, 20:, : ] = img[20:, 20:, : ]\n",
    "\n",
    "f, axarr = plt.subplots(1,6, figsize=(15,40))\n",
    "axarr[0].imshow(img)\n",
    "axarr[1].imshow(img_lowres)\n",
    "axarr[2].imshow(img_rot)\n",
    "axarr[3].imshow(img_fade)\n",
    "axarr[4].imshow(img_flip)\n",
    "axarr[5].imshow(img_shift)\n",
    "\n",
    "for ax,title in zip(axarr, ['Original', 'Low Resolution', 'Rotation 180', 'Low Intensity', 'Flip', 'Shift']):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$ \\displaystyle SSIM(x,y) = \\frac{(2\\mu_x\\mu_y + C_1) + (2 \\sigma _{xy} + C_2)} \n",
    "    {(\\mu_x^2 + \\mu_y^2+C_1) (\\sigma_x^2 + \\sigma_y^2+C_2)}$, where we define $11\\times 11$ windows as $x$ and $y$ from two images and\n",
    "\n",
    "${\\displaystyle \\mu _{x}}$ the pixel sample mean of ${\\displaystyle x}$;\n",
    "\n",
    "${\\displaystyle \\mu _{y}}$ the pixel sample mean of ${\\displaystyle y}$; \n",
    "\n",
    "${\\displaystyle \\sigma _{x}^{2}}$ the variance of ${\\displaystyle x}$; \n",
    "\n",
    "${\\displaystyle \\sigma _{y}^{2}}$ the variance of ${\\displaystyle y}$; \n",
    "\n",
    "${\\displaystyle \\sigma _{xy}}$ the covariance of  ${\\displaystyle x}$ and ${\\displaystyle y}$; \n",
    "\n",
    "${\\displaystyle c_{1}=(k_{1}L)^{2}}$, $ {\\displaystyle c_{2}=(k_{2}L)^{2}}$ two variables to stabilize the division with weak denominator; \n",
    "\n",
    "${\\displaystyle L}$ the dynamic range of the pixel-values; \n",
    "\n",
    "${\\displaystyle k_{1}=0.01}$ and ${\\displaystyle k_{2}=0.03}$ by default.\n",
    "\n",
    "\n",
    "**Hints:** \n",
    "- `cv2.getGaussianKernel(size, sigma)` generates 1D gaussian kernel \n",
    "- `cv2.filter2D(input, -1, kernel)` operates the convolution on the input with the kernel\n",
    "- $\\mathrm{Var}(X) = \\mathrm{E}[X^2] - \\mathrm{E}[X]^2$\n",
    "- Note that we will use a Gaussian kernel ($11\\times 11$) to calculate means and variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM\n",
    "import cv2\n",
    "\n",
    "# Your Code Here\n",
    "# def SSIM_(img1, img2):\n",
    "#     C1 = \n",
    "#     C2 = \n",
    "\n",
    "#     kernel_1D =\n",
    "#     kernel_2D = kernel_1D @ kernel_1D.T\n",
    "\n",
    "#     mu1 = \n",
    "#     mu2 = \n",
    "\n",
    "#     var1 = \n",
    "#     var2 = \n",
    "#     covar12 = \n",
    "\n",
    "#     ssim = ((2 * mu1 * mu2 + C1) * (2 * covar12 + C2)) / ((mu1**2 + mu2**2 + C1) * (var1 + var2 + C2))  # you are welcome ;)\n",
    "#     return ssim.mean()\n",
    "\n",
    "\n",
    "print(f'{\"Low res:\": <10} {SSIM_(img, img_lowres):.4f}')\n",
    "print(f'{\"Rotation:\": <10} {SSIM_(img, img_rot):.4f}')\n",
    "print(f'{\"Intensity:\": <10} {SSIM_(img, img_fade):.4f}')\n",
    "print(f'{\"Flip:\": <10} {SSIM_(img, img_flip):.4f}')\n",
    "print(f'{\"Shift:\": <10} {SSIM_(img, img_shift):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the SSIM from torchmetrics. Note that you have to convert the numpy arrays [W,H,C] to torch tensors [B,C,W,H].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM\n",
    "# Use torchmetrics\n",
    "# Your Code Here\n",
    "\n",
    "# def np_whc_to_tensor_bcwh(img_np_whc):\n",
    "# \n",
    "#     return img_tensor_bcwh\n",
    "\n",
    "# img = np_whc_to_tensor_bcwh(img)\n",
    "# img_lowres = np_whc_to_tensor_bcwh(img_lowres)\n",
    "# img_rot = np_whc_to_tensor_bcwh(img_rot)\n",
    "# img_fade = np_whc_to_tensor_bcwh(img_fade)\n",
    "# img_flip = np_whc_to_tensor_bcwh(img_flip.copy()) \n",
    "# img_shift = np_whc_to_tensor_bcwh(img_shift)\n",
    "\n",
    "# ssim =    # instantiate the ssim from torchmetrics\n",
    "\n",
    "\n",
    "print(f'{\"Low res:\": <10} {ssim(img, img_lowres):.4f}')\n",
    "print(f'{\"Rotation:\": <10} {ssim(img, img_rot):.4f}')\n",
    "print(f'{\"Intensity:\": <10} {ssim(img, img_fade):.4f}')\n",
    "print(f'{\"Flip:\": <10} {ssim(img, img_flip):.4f}')\n",
    "print(f'{\"Shift:\": <10} {ssim(img, img_shift):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Summarize some characristics of SSIM based on these examples. Are the SSIM values in accordance with your intuitions?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback Cell:\n",
    "Let us know how you liked it. Any suggestions/ criticism are also welcome! \n",
    "\n",
    "Your feedbacks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: PSNR\n",
    "You can implement PSNR and calculate it with the image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSNR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "The cat picture is licensed with [CC BY-SA 2.0 DEED](https://creativecommons.org/licenses/by-sa/2.0/deed.en) from https://w.wiki/9hFn. The dog picture is licensed with [CC BY-SA 4.0 DEED](https://creativecommons.org/licenses/by-sa/4.0/) from [The Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). The libraries used are numpy, pytorch, torchmetrics, opencv. \n",
    "\n",
    "Contributor(s): Yuli Wu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
