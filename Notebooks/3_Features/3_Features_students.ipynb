{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HaMLeT\n",
    "\n",
    "## Session 3: Feature Extraction\n",
    "\n",
    "### Goals of this Session\n",
    "\n",
    "In this session you will ...\n",
    "* get an understanding of why feature descriptors are superior to raw data\n",
    "* be able to think of abstract representations of image data\n",
    "* have implemented a feature descriptor on your own\n",
    "* have gotten to know several common descriptors\n",
    "* have used feature representations for image classifciation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Pattern\n",
    "\n",
    "Local Binary Pattern is a simple feature descriptor. It compares the eight neighbouring pixel values to the center pixel value -- if it's larger, the value 1 is assigned to this pixel and 0 otherwise. The resulting 8 bit number is stored as an integer (in the range of 0--255). This is the local feature descriptor for a single pixel. For this exercise, the least significant bit should be in the upper right corner and the significance increases clockwise.\n",
    "\n",
    "Useful hints:\n",
    "* `2 ** 7` computes 2^7.\n",
    "* There is `+=` operator in python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Implement Local Binary Pattern and test it on a few random 3x3 matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def local_binary_pattern(input_matrix):\n",
    "    # input matrix is a numpy array of size 3 x 3\n",
    "    # return value should be an integer number between 0 and 255.\n",
    "    return lbp\n",
    "\n",
    "# Test with some random numbers\n",
    "for i in range(5):\n",
    "    random_matrix = np.random.randint(255, size=(3, 3))\n",
    "    lbp = local_binary_pattern(random_matrix)\n",
    "    print('Random Matrix:\\n', random_matrix, '\\nLBP: ', lbp, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to use this local feature descriptor to convert an entire image to a more compact representation of itself. Often, LBP is used with a histogram.\n",
    "\n",
    "Useful hints:\n",
    "\n",
    "* `numpy` has a `histogram` function!\n",
    "* Use the for-loop and ignore the border pixels (no padding required)\n",
    "\n",
    "**Task:** Implement Local Binary Pattern for a whole image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_binary_pattern_histogram(input_image):\n",
    "    # input_image is an image of arbitrary size\n",
    "    # return a 256 entires long list or array that contains \n",
    "    # the local binary pattern histogram values.\n",
    "    for i in range(1, input_image.shape[0] - 1):\n",
    "        for j in range(1, input_image.shape[1] - 1):\n",
    "            # your code here\n",
    "    histogram = []\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# this is just a sample image (and we'll only take the first channel\n",
    "# as it's grayscale, it's the same as the other two channels anyway)\n",
    "sample_image = cv2.imread('sample.jpg')[:, :, 0]\n",
    "hist = local_binary_pattern_histogram(sample_image)\n",
    "\n",
    "pyplot.bar(range(256), hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an abstract representation of our image! Instead of using 512 x 512 = 262'144 raw intensity values, we've condensed the image into a feature vector of length 256.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification \n",
    "\n",
    "We'd like to use feature descriptors such as LBP for image classification. In this section you'll apply feature descriptors to images and use a simple classifier to assign one of two classes to the image.\n",
    "\n",
    "Before we can start, we have to overcome a few challenges. First of all, the dataset contains images of arbitrary size. Usually, you either extract images from patches with a fixed size or you implement feature detectors that are size independent. The latter can be done for example by normalising the histogramm. Normalising / scaling feature values is generally a good practise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Write a normalisation method that normalises a given histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_histogram(hist):\n",
    "    normalised_histogram = []\n",
    "    return normalised_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use this, but we'll also extract image patches (some methods later require that). In this case, we'll extract only one large, square patch per image and resize it to a fixed size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a method that preprocesses the image by \n",
    "* converting to grayscale\n",
    "* extracting a square patch from the centre\n",
    "* resize the patch to a given fixed size.\n",
    "\n",
    "Take a look at it to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patch(input_image, fixed_size=256):\n",
    "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    tmp_size = min(gray_image.shape)\n",
    "    offsets = [(gray_image.shape[i] - tmp_size) // 2 for i in (0, 1)]\n",
    "    patch = gray_image[offsets[0]: offsets[0] + tmp_size, offsets[1]: offsets[1] + tmp_size]\n",
    "    return cv2.resize(patch, (fixed_size, fixed_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how it works with a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = cv2.imread('sample_large.jpg')\n",
    "patch = extract_patch(sample_image)\n",
    "pyplot.imshow(patch, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our dataset!\n",
    "We'll use [CalTech 101](http://www.vision.caltech.edu/Image_Datasets/Caltech101) dataset, which contains images from 101 classes of object. For this task, we'll try to create a classifier that can distinguish soccer balls and pyramids. Here is a method that returns four list of image data: two with labels (0 = emu, 1 = mayfly) and two with the actual images for training and testing, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import Caltech101\n",
    "import os, glob\n",
    "\n",
    "dset_path = os.path.join(os.path.abspath(os.environ[\"HOME\"]), 'datasets')\n",
    "if not os.path.exists(os.path.join(dset_path, 'caltech101', '101_ObjectCategories')):\n",
    "    ds = Caltech101(dset_path, download=True)\n",
    "    \n",
    "def load_dataset(train_percentage=0.7, maxnum=1000):\n",
    "    images, labels = [], []\n",
    "    for labelNum, labelName in enumerate(['emu', 'mayfly']):\n",
    "        cnt = 0\n",
    "        image_list = glob.glob(os.path.join(dset_path, 'caltech101', '101_ObjectCategories', labelName, '*.jpg'))\n",
    "        for imagePath in image_list[:maxnum]:\n",
    "            images.append(cv2.imread(imagePath))\n",
    "            labels.append(labelNum)\n",
    "            cnt += 1\n",
    "        print('Loaded ', cnt, ' images of class ', labelName)\n",
    "    np.random.seed(11)\n",
    "    np.random.shuffle(images)\n",
    "    np.random.seed(11)\n",
    "    np.random.shuffle(labels)\n",
    "    split = int(len(labels) * train_percentage)\n",
    "    return np.array(images[:split]), np.array(labels[:split]), np.array(images[split:]), np.array(labels[split:])\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise a few of these images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['emu', 'mayfly']\n",
    "\n",
    "print(label_names[train_labels[0]])\n",
    "print(label_names[test_labels[0]])\n",
    "print(label_names[train_labels[1]])\n",
    "print(label_names[test_labels[1]])\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.imshow(train_data[0])\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.imshow(test_data[0])\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.imshow(train_data[1])\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.imshow(test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** convert the train and test data into a suitable format and apply feature extraction with a normalised local binary pattern histogram. For a good trade-off between computational performance and accuracy, use an image size of 256 x 256 pixels.\n",
    "\n",
    "Useful hints:\n",
    "\n",
    "* data is a list of images -- for each item in the list, extract the patch and compute the feature vector of the patch\n",
    "* list comprehensions are amazing: `new_list = [operation(item) for item in old_list]` should be really useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vectors(data):\n",
    "    # data is a list of images, feature_data is a list of corresponding feature vectors\n",
    "    feature_data = []\n",
    "    return feature_data\n",
    "\n",
    "train_features = np.array(create_feature_vectors(train_data))\n",
    "test_features = np.array(create_feature_vectors(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's get to the fun part: Classification! You know how to handle this, the only difference is that we'll use our own features extracted from images instead of precomputed ones. Don't worry if the numbers have no real meaning to you anymore -- as long as they provide a good separation between the classes, we'll be fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Implement methods to train and test classification using feature descriptors with an SVM!\n",
    "\n",
    "Useful hints:\n",
    "\n",
    "* you can write methods on your own, but `sklearn` has stuff like `sklearn.preprocessing.StandardScaler` and `sklearn.metrics.accuracy_score` built in already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_and_test(train_data, train_labels, test_data, test_labels):\n",
    "    # use a linear SVM, a StandardScaler and return the accuracy!\n",
    "    accuracy = 0\n",
    "    return accuracy\n",
    "\n",
    "print('Test Features')\n",
    "train_and_test(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare that to the original raw data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = [extract_patch(datum, fixed_size=256).reshape(-1) for datum in train_data]\n",
    "test_raw = [extract_patch(datum, fixed_size=256).reshape(-1) for datum in test_data]\n",
    "\n",
    "print('Test Raw')\n",
    "train_and_test(train_raw, train_labels, test_raw, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, we're at least a little better than raw data. \n",
    "\n",
    "Let's check some other feature descriptors. Many of them are already implemented, for example in `scikit image`. Let's check their implementation of the LBP feature descriptor.\n",
    "\n",
    "**Task:** Write a method that converts a list of images into a list of lbp features using the `skimage_lbp` method. Read up in the documentation about variations and implement a `uniform` version. Remember to also implement histogram functions with arbitrary lengths, as the `uniform` variant returns fewer than 256 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern as skimage_lbp\n",
    "\n",
    "def skimage_lbp_histogram(input_image):\n",
    "    # input_image is an image of arbitrary size\n",
    "    # return a 256 entires long list or array that contains the \n",
    "    # local binary pattern histogram values.\n",
    "    lbp_histogram = []\n",
    "    return lbp_histogram\n",
    "\n",
    "def create_feature_vectors(data):\n",
    "    # data is a list of images, feature_data is a list of corresponding feature vectors\n",
    "    # list comprehensions are a pythonic way to handle lists, btw. It might come in handy here!\n",
    "    feature_data = []\n",
    "    return feature_data\n",
    "\n",
    "sample_image = cv2.imread('sample.jpg')[:, :, 0]\n",
    "hist = skimage_lbp_histogram(sample_image)\n",
    "pyplot.bar(range(len(hist)), hist)\n",
    "\n",
    "train_features = np.array(create_feature_vectors(train_data), dtype=np.float64)\n",
    "test_features = np.array(create_feature_vectors(test_data), dtype=np.float64)\n",
    "\n",
    "print('Test Features')\n",
    "train_and_test(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Use the new features to perform classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: Even if the results with feature descriptors are slightly poorer (which may also be due to a small and unsuitable training set), applying features has several advantages. Use the `uniform` version of LBP to explain some of them.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:** ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Feature Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image processing, there are several feature descriptors that common and already implemented -- just like the LBP descriptor you saw earlier. \n",
    "\n",
    "**Task:** Try the HOG feature descriptor. How well does it perform? Use the `visualise=True` parameter and visualise the result of the feature descriptor.\n",
    "\n",
    "*Question:* What do you see, how can you interpret the HOG features? What is your opinion about the number of returned features?\n",
    "**Your answer:** ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog as skimage_hog\n",
    "\n",
    "def create_feature_vectors(data):\n",
    "    # data is a list of images, feature_data is a list of corresponding feature vectors\n",
    "    feature_data = []\n",
    "    return feature_data\n",
    "\n",
    "\n",
    "sample_image = cv2.imread('sample.jpg')\n",
    "# implement img such that img is a representation of hog\n",
    "pyplot.imshow(img)\n",
    "\n",
    "hist = skimage_hog(extract_patch(sample_image, fixed_size=24), block_norm='L2-Hys')\n",
    "print(len(hist))\n",
    "pyplot.figure()\n",
    "pyplot.bar(range(len(hist)), hist)\n",
    "\n",
    "train_features = np.array(create_feature_vectors(train_data), dtype=np.float64)\n",
    "test_features = np.array(create_feature_vectors(test_data), dtype=np.float64)\n",
    "\n",
    "print('Test Features')\n",
    "train_and_test(train_features, train_labels, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, it is useful to combine several features into one larger feature detector.\n",
    "\n",
    "**Task:** Combine HOG, LBP and other feature descriptors in a useful way and see how it performs.\n",
    "\n",
    "Useful hints:\n",
    "\n",
    "* 'useful' in this case means concatenating lists\n",
    "* you can concatenate two lists `list1` and `list2` into `list1` by using `extend`: `list1.extend(list2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_features(input_image):\n",
    "    # compute a list that contains the entries of several feature vectors\n",
    "    combined_features = []\n",
    "    return combined_features\n",
    "\n",
    "def create_feature_vectors(data):\n",
    "    # data is a list of images, feature_data is a list of corresponding feature vectors\n",
    "    feature_data = []\n",
    "    return feature_data\n",
    "\n",
    "sample_image = cv2.imread('sample.jpg')\n",
    "hist = combined_features(sample_image)\n",
    "print(len(hist))\n",
    "pyplot.bar(range(len(hist)), hist)\n",
    "\n",
    "train_features = np.array(create_feature_vectors(train_data), dtype=np.float64)\n",
    "test_features = np.array(create_feature_vectors(test_data), dtype=np.float64)\n",
    "\n",
    "print('Test Features')\n",
    "train_and_test(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question:* You have used a StandardScaler (I hope). Why is this important -- particularly in this case?\n",
    "\n",
    "**Your answer**: ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Exercises\n",
    "\n",
    "If you're fast, there are some more interesting and challenging tasks for you! Here we go:\n",
    "\n",
    "##### Some other SKImage Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Try out other feature descriptors you find out, which are useful. Try to describe why / why not. You can find inspiration in this list of features (or useful methods to create features) in `skimage`: http://scikit-image.org/docs/dev/api/skimage.feature.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_other_skimage_features(input_image):\n",
    "    features = []\n",
    "    return features\n",
    "    \n",
    "def create_feature_vectors(data):\n",
    "    # data is a list of images, feature_data is a list of corresponding feature vectors\n",
    "    feature_data = []\n",
    "    return feature_data\n",
    "\n",
    "# sample_image = cv2.imread('sample.jpg')\n",
    "# hist = some_other_skimage_features(sample_image)\n",
    "# print(hist)\n",
    "\n",
    "# train_features = np.array(create_feature_vectors(train_data), dtype=np.float64)\n",
    "# test_features = np.array(create_feature_vectors(test_data), dtype=np.float64)\n",
    "\n",
    "\n",
    "# print('Test Features')\n",
    "# train_and_test(train_features, train_labels, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question:* Based on the experiences you made in this session, what would you say are important properties of feature descriptors?\n",
    "\n",
    "**Your answer:** ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Change the two classes `emu` and `mayfly` in the dataloader (just replace the name with any foldername in `101_ObjectCategories` on your drive) and see, which classes can be separated well with which kind of descriptor. How can you explain the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LBP Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several improvements to Local Binary Pattern, for example you could ...\n",
    "* compare to other values than the center value (e.g. to the mean / median of the patch)\n",
    "* use a larger radius than one to choose neighbour pixels\n",
    "* use a look-up table for rotation invariance and other cool stuff (google for 'uniform local binary pattern')\n",
    "\n",
    "**Task:** Implement one improvement to local binary pattern of your own choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_local_binary_pattern(input_image):\n",
    "    # input_image is an image of arbitrary size\n",
    "    # return a list or array that contains the improved local binary pattern feature \n",
    "    # for the entire image\n",
    "    ilbp = []\n",
    "    return ilbp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your descriptor against standard LBP and see how it performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You've written all the code necessary for this already. \n",
    "# Copy paste is a programmer's best friend ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your own descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBP is a rather simple feature descriptor, yet it is still often very effective. Think of other simple ways that could describe an image better than raw intensity values. \n",
    "\n",
    "**Task:** Implement a feature descriptor (or more general: a method that return a short list of values that describe an image) on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_own_feature_descriptor(input_image):\n",
    "    feat = []\n",
    "    return feat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Perform classification with your own feature descriptor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You've written all the code necessary for this already. \n",
    "# Copy paste is a programmer's best friend ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "\n",
    "Please give us some feedback about this session:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_enter feedback here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}